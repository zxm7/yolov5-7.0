# ga_enhance/ga_main.py
# =========================================================
# âœ… GA ä¸»å¾ªç¯ï¼ˆæ”¯æŒå¹¶è¡Œè¯„ä¼°ï¼‰
#
# ä½ è¦çš„ç»ˆç«¯è¿‡ç¨‹è¾“å‡ºåŒ…æ‹¬ï¼š
# - å½“å‰ç¬¬å‡ ä»£ / æ€»ä»£æ•°
# - ç¬¬å‡ ä¸ªä¸ªä½“ / æ€»ä¸ªä½“æ•°
# - å½“å‰ä¸ªä½“ mAPã€è€—æ—¶ã€æ˜¯å¦å‘½ä¸­ç¼“å­˜
# - æ¯ä»£ç»“æŸï¼šbest / mean / std / global_best
# - å…¨å±€æœ€ä¼˜æ›´æ–°æç¤ºï¼ˆæ‰“å° best paramsï¼‰
#
# ä½ è¦çš„â€œä»¥ååªæ”¹ä¸€å¤„å‚æ•°â€ä¹Ÿæ»¡è¶³ï¼š
# - DIM / decode_params éƒ½æ¥è‡ª enhance_ops.py
#
# æ§ç›˜ç­–ç•¥ï¼š
# - æ¯ä»£ç»“æŸæ¸…ç†ç¼“å­˜ï¼š
#   åªä¿ç•™æœ€è¿‘ KEEP_RECENT_SUCCESS ä¸ªæˆåŠŸ work_dir + å…¨å±€ best work_dir
#   å¤±è´¥ work_dir é»˜è®¤ç›´æ¥åˆ é™¤ï¼ˆDELETE_FAIL_CACHEï¼‰
# =========================================================

from __future__ import annotations

import os
import re
import csv
import json
import time
import shutil
from pathlib import Path
from datetime import datetime
from typing import List, Tuple

import numpy as np
from multiprocessing import Pool

from .enhance_ops import DIM, decode_params
from .eval_yolo import evaluate_params, EvalResult, CACHE_DIR

# -------------------------------
# 0) GA è¶…å‚æ•°ï¼ˆä½ å¯ä»¥è°ƒï¼‰
# -------------------------------
POP_SIZE = 50
N_GEN = 30
ELITE = 1               # ç²¾è‹±ä¿ç•™æ•°é‡
TOURNAMENT_K = 3        # é”¦æ ‡èµ›é€‰æ‹©è§„æ¨¡
CX_PROB = 0.8           # äº¤å‰æ¦‚ç‡
MUT_PROB = 0.03          # å˜å¼‚æ¦‚ç‡
MUT_SIGMA = 0.15        # å˜å¼‚å¼ºåº¦ï¼ˆå¯¹ [0,1] ç©ºé—´åŠ é«˜æ–¯å™ªå£°ï¼‰
SEED = None

# -------------------------------
# 1) å¹¶è¡Œè®¾ç½®ï¼ˆå›ºå®š 2ï¼‰
# -------------------------------
N_WORKERS = 12
QUIET_ENHANCE = True    # å¹¶è¡Œæ—¶å»ºè®® Trueï¼šé¿å… 2 ä¸ªè¿›ç¨‹ä¸€èµ·åˆ·å±

# -------------------------------
# 2) ç¼“å­˜æ§ç›˜è®¾ç½®
# -------------------------------
KEEP_RECENT_SUCCESS = 12
DELETE_FAIL_CACHE = True

# -------------------------------
# 3) æ—¥å¿—è¾“å‡ºç›®å½•
# -------------------------------
LOG_ROOT = Path(__file__).resolve().parents[1] / "ga_logs"
LOG_ROOT.mkdir(parents=True, exist_ok=True)

def _next_run_dir(start_idx: int = 4) -> Path:
    """
    run ç¼–å·è‡ªåŠ¨é€’å¢ï¼ˆé‡å¯/å…³æœºä¸å½±å“ï¼‰
    """
    existing = []
    for p in LOG_ROOT.glob("run*"):
        m = re.match(r"run(\d+)$", p.name)
        if m:
            existing.append(int(m.group(1)))
    run_id = max(existing, default=start_idx - 1) + 1
    run_dir = LOG_ROOT / f"run{run_id}"
    run_dir.mkdir(parents=True, exist_ok=True)
    return run_dir

def _clip01(x: np.ndarray) -> np.ndarray:
    return np.clip(x, 0.0, 1.0)

def _init_pop(rng: np.random.Generator) -> np.ndarray:
    """
    åˆå§‹åŒ–ç§ç¾¤ï¼šPOP_SIZE Ã— DIMï¼Œå‡åŒ€éšæœº [0,1]
    """
    return rng.random((POP_SIZE, DIM), dtype=np.float32)

def _tournament_select(pop: np.ndarray, fit: np.ndarray, rng: np.random.Generator) -> np.ndarray:
    """
    é”¦æ ‡èµ›é€‰æ‹©ï¼šéšæœºæŠ½ K ä¸ªï¼Œé€‰é€‚åº”åº¦æœ€é«˜è€…
    """
    idxs = rng.integers(0, len(pop), size=TOURNAMENT_K)
    best = idxs[np.argmax(fit[idxs])]
    return pop[best].copy()

def _crossover(a: np.ndarray, b: np.ndarray, rng: np.random.Generator) -> Tuple[np.ndarray, np.ndarray]:
    """
    uniform crossoverï¼ˆå‡åŒ€äº¤å‰ï¼‰
    """
    if rng.random() > CX_PROB:
        return a.copy(), b.copy()

    mask = rng.random(DIM) < 0.5
    c1 = a.copy()
    c2 = b.copy()
    c1[mask] = b[mask]
    c2[mask] = a[mask]
    return c1, c2

def _mutate(x: np.ndarray, rng: np.random.Generator) -> np.ndarray:
    """
    é«˜æ–¯å˜å¼‚ï¼šå¯¹æŸ“è‰²ä½“åŠ å™ªå£°ï¼Œç„¶åè£å‰ªå› [0,1]
    """
    if rng.random() > MUT_PROB:
        return x
    noise = rng.normal(0.0, MUT_SIGMA, size=DIM).astype(np.float32)
    y = x + noise
    return _clip01(y)

def _format_params(params: dict) -> str:
    """
    æŠŠ params dict æ ¼å¼åŒ–æˆä¸€è¡Œå¯è¯»æ–‡æœ¬
    """
    return ", ".join([f"{k}={float(v):.4f}" for k, v in params.items()])

def _cleanup_cache(keep_success_dirs: List[Path], keep_best_dir: Path | None):
    """
    æ¸…ç† ga_cacheï¼šåªä¿ç•™æŒ‡å®šæˆåŠŸç›®å½• + best ç›®å½•
    """
    keep = set([p.resolve() for p in keep_success_dirs])
    if keep_best_dir is not None:
        keep.add(keep_best_dir.resolve())

    removed = 0
    failed_removed = 0

    for wd in CACHE_DIR.glob("work_*"):
        if not wd.is_dir():
            continue
        # ä¿ç•™åå•
        if wd.resolve() in keep:
            continue

        # å¤±è´¥ç¼“å­˜ï¼šå¯é€‰æ‹©ç›´æ¥åˆ 
        if (wd / "FAIL").exists() and DELETE_FAIL_CACHE:
            shutil.rmtree(wd, ignore_errors=True)
            removed += 1
            failed_removed += 1
            continue

        # æˆåŠŸç¼“å­˜ï¼šå¦‚æœä¸åœ¨ä¿ç•™åå•é‡Œä¹Ÿåˆ ï¼ˆæ§ç›˜ï¼‰
        if (wd / "DONE").exists():
            shutil.rmtree(wd, ignore_errors=True)
            removed += 1
            continue

        # RUNNING æˆ–å…¶å®ƒå¼‚å¸¸ç›®å½•ï¼šä¿å®ˆèµ·è§ä¸åˆ ï¼ˆä½ ä¹Ÿå¯æ”¹æˆåˆ ï¼‰
        # è¿™é‡Œé€‰æ‹©è·³è¿‡

    print(f"[ç¼“å­˜æ¸…ç†] åˆ é™¤ {removed} ä¸ªç›®å½•ï¼ˆå…¶ä¸­ FAIL={failed_removed}ï¼‰")

def main():
    rng = np.random.default_rng(SEED)

    run_dir = _next_run_dir(start_idx=4)
    run_name = run_dir.name

    # ga_history.csv
    hist_csv = run_dir / "ga_history.csv"
    best_json = run_dir / "best.json"

    # è®°å½•è¡¨å¤´ï¼šåŸºå› åˆ— + è§£ç å‚æ•°åˆ— + ç»“æœåˆ—
    # å‚æ•°åˆ—åæ¥è‡ª decode_params(0.5...0.5)ï¼Œç¡®ä¿ä¸ä½ å¢å¼ºä¸€è‡´
    sample_params = decode_params(np.full((DIM,), 0.5, dtype=np.float32))
    param_cols = list(sample_params.keys())
    gene_cols = [f"g{i}" for i in range(DIM)]

    header = [
        "gen", "idx_in_gen", "global_eval_idx", "eval_tag",
        *gene_cols,
        *param_cols,
        "map50", "map50_95", "eval_time_sec", "ok", "cache_hit", "work_dir"    # ğŸŸ¢ å¢åŠ  map50_95
    ]

    # åˆå§‹åŒ– CSV
    if not hist_csv.exists():
        with hist_csv.open("w", newline="", encoding="utf-8") as f:
            csv.writer(f).writerow(header)

    # åˆå§‹åŒ–ç§ç¾¤
    pop = _init_pop(rng)

    # å…¨å±€ best
    global_best_map = -1.0
    global_best_chrom: List[float] = []
    global_best_params: dict = {}
    global_best_work_dir: Path | None = None

    global_eval_idx = 0
    recent_success_work_dirs: List[Path] = []  # æ§ç›˜ï¼šè®°å½•æœ€è¿‘æˆåŠŸç¼“å­˜

    print("=" * 60)
    print(f"[GAå¯åŠ¨] run_dir={run_dir}")
    print(f"[GAå¯åŠ¨] POP_SIZE={POP_SIZE}, N_GEN={N_GEN}, DIM={DIM}, N_WORKERS={N_WORKERS}")
    print("=" * 60)

    # è¿›ç¨‹æ± ï¼ˆå¹¶è¡Œè¯„ä¼°ä¸ªä½“ï¼‰
    with Pool(processes=N_WORKERS) as pool:
        for gen in range(N_GEN):
            print("\n" + "-" * 60)
            print(f"[ç¬¬ {gen+1}/{N_GEN} ä»£] å¼€å§‹è¯„ä¼° {POP_SIZE} ä¸ªä½“...")
            print("-" * 60)

            # è¿™ä¸€ä»£è¦è¯„ä¼°çš„ä»»åŠ¡åˆ—è¡¨
            tasks = []
            for i in range(POP_SIZE):
                global_eval_idx += 1
                # eval_tagï¼šå»ºè®®åŒ…å« run + pidï¼ˆä¸»è¿›ç¨‹ pidï¼‰+ eval_idx
                # æ³¨æ„ï¼šè¿™é‡Œçš„ pid æ˜¯ä¸»è¿›ç¨‹çš„ pidï¼Œä»…ç”¨äº tag å”¯ä¸€ï¼Œä¸å½±å“å¹¶è¡Œå®‰å…¨
                eval_tag = f"{run_name}_p{os.getpid()}_e{global_eval_idx}"
                chrom = pop[i].copy()
                tasks.append((i, global_eval_idx, eval_tag, chrom))

            # æäº¤å¹¶è¡Œè¯„ä¼°
            async_results = []
            for (idx_in_gen, gei, tag, chrom) in tasks:
                async_results.append((
                    idx_in_gen, gei, tag, chrom,
                    pool.apply_async(
                        evaluate_params,
                        kwds=dict(chrom=chrom, eval_tag=tag, force_rebuild=False, quiet_enhance=False)
                    )
                ))

            # æ”¶é›†ç»“æœï¼ˆæŒ‰æäº¤é¡ºåºæ”¶é›†ï¼Œç»ˆç«¯è¾“å‡ºæ›´ç¨³å®šï¼‰
            fitness = np.full((POP_SIZE,), -1.0, dtype=np.float32)
            gen_maps = []
            gen_ok = 0
            gen_cache_hit = 0

            for k, (idx_in_gen, gei, tag, chrom, ar) in enumerate(async_results, start=1):
                # ç­‰å¾…å•ä¸ªç»“æœè¿”å›ï¼ˆå¹¶è¡Œå¿…é¡»â€œç­‰â€ï¼Œå¦åˆ™è¿™ä¸€ä»£æ— æ³•åšé€‰æ‹©/äº¤å‰/å˜å¼‚ï¼‰
                res: EvalResult = ar.get()

                params = decode_params(chrom)  # è®°å½•ç”¨ï¼ˆä¸å¢å¼ºä¸€è‡´ï¼‰
                row = [
                    gen, idx_in_gen, gei, tag,
                    *[float(x) for x in chrom.tolist()],
                    *[float(params[c]) for c in param_cols],
                    float(res.map50),
                    float(res.map50_95),  # ğŸŸ¢ å¢åŠ è¿™è¡Œæ•°æ®å†™å…¥
                    float(res.time_sec),
                    int(res.ok), int(res.cache_hit), res.work_dir
                ]

                # å†™ CSVï¼ˆæ¯ä¸ªä¸ªä½“ç«‹å³è½ç›˜ï¼Œé˜²æ­¢ä¸­é€”å´©æºƒä¸¢æ•°æ®ï¼‰
                with hist_csv.open("a", newline="", encoding="utf-8") as f:
                    csv.writer(f).writerow(row)

                # ç»ˆç«¯è¿‡ç¨‹æ€§è¾“å‡ºï¼ˆä½ è¦çš„é‡ç‚¹ï¼ï¼‰
                status = "OK" if res.ok == 1 else "FAIL"
                hit = "HIT" if res.cache_hit == 1 else "MISS"
                print(f"[è¿›åº¦] gen={gen+1}/{N_GEN} ä¸ªä½“={idx_in_gen+1}/{POP_SIZE} "
                      f"({k}/{POP_SIZE}) çŠ¶æ€={status} cache={hit} "
                      f"mAP50={res.map50:.4f} time={res.time_sec:.1f}s")

                if res.ok == 1:
                    fitness[idx_in_gen] = 0.7 * res.map50 + 0.3 * res.map50_95
                    gen_maps.append(res.map50)
                    gen_ok += 1
                    gen_cache_hit += res.cache_hit

                    # æ§ç›˜è®°å½•ï¼šæˆåŠŸçš„ work_dir
                    wd = Path(res.work_dir)
                    recent_success_work_dirs.append(wd)
                    # åªä¿ç•™æœ€è¿‘ KEEP_RECENT_SUCCESS ä¸ª
                    if len(recent_success_work_dirs) > KEEP_RECENT_SUCCESS:
                        recent_success_work_dirs = recent_success_work_dirs[-KEEP_RECENT_SUCCESS:]

                    # å…¨å±€ best æ›´æ–°
                    if res.map50 > global_best_map:
                        global_best_map = res.map50
                        global_best_chrom = chrom.tolist()
                        global_best_params = params
                        global_best_work_dir = wd

                        print("â­" * 60)
                        print(f"[å…¨å±€æœ€ä¼˜æ›´æ–°] NEW BEST! mAP50={global_best_map:.4f}")
                        print(f"[å…¨å±€æœ€ä¼˜æ›´æ–°] chrom={global_best_chrom}")
                        print(f"[å…¨å±€æœ€ä¼˜æ›´æ–°] params=({_format_params(global_best_params)})")
                        print("â­" * 60)

            # ä¸€ä»£æ±‡æ€»
            if gen_maps:
                best_gen = float(np.max(gen_maps))
                mean_gen = float(np.mean(gen_maps))
                std_gen = float(np.std(gen_maps))
            else:
                best_gen, mean_gen, std_gen = -1.0, -1.0, -1.0

            print("-" * 60)
            print(f"[ç¬¬ {gen+1} ä»£ç»“æŸ] OKä¸ªä½“={gen_ok}/{POP_SIZE}, cacheå‘½ä¸­={gen_cache_hit}/{gen_ok if gen_ok else 1}")
            print(f"[ç¬¬ {gen+1} ä»£ç»Ÿè®¡] best={best_gen:.4f} mean={mean_gen:.4f} std={std_gen:.4f} | global_best={global_best_map:.4f}")
            print("-" * 60)

            # æ§ç›˜æ¸…ç†ï¼ˆæ¯ä»£ç»“æŸåšä¸€æ¬¡ï¼‰
            _cleanup_cache(recent_success_work_dirs, global_best_work_dir)

            # å¦‚æœè¿™ä¸€ä»£å…¨å¤±è´¥ï¼šç›´æ¥é‡æ–°éšæœºä¸€ä»£ï¼Œé¿å… GA æ–­æ‰
            if np.all(fitness < 0):
                print("[è­¦å‘Š] æœ¬ä»£å…¨éƒ¨è¯„ä¼°å¤±è´¥ï¼ˆå…¨æ˜¯ -1ï¼‰ã€‚å°†é‡æ–°éšæœºç§ç¾¤ç»§ç»­è·‘ã€‚")
                pop = _init_pop(rng)
                continue

            # ç”Ÿæˆä¸‹ä¸€ä»£ï¼šç²¾è‹±ä¿ç•™ + é€‰æ‹©/äº¤å‰/å˜å¼‚
            next_pop = []

            # ç²¾è‹±
            elite_idx = np.argsort(fitness)[::-1][:ELITE]
            for ei in elite_idx:
                next_pop.append(pop[ei].copy())

            # å…¶ä½™é€šè¿‡é—ä¼ æ“ä½œäº§ç”Ÿ
            while len(next_pop) < POP_SIZE:
                p1 = _tournament_select(pop, fitness, rng)
                p2 = _tournament_select(pop, fitness, rng)
                c1, c2 = _crossover(p1, p2, rng)
                c1 = _mutate(c1, rng)
                c2 = _mutate(c2, rng)
                next_pop.append(c1)
                if len(next_pop) < POP_SIZE:
                    next_pop.append(c2)

            pop = np.stack(next_pop, axis=0).astype(np.float32)

    # ä¿å­˜ best.jsonï¼ˆåŒ…å« GA é‡è¦è¶…å‚ï¼‰
    best_payload = {
        "run_dir": str(run_dir),
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "DIM": DIM,
        "GA_hyperparams": {
            "POP_SIZE": POP_SIZE,
            "N_GEN": N_GEN,
            "ELITE": ELITE,
            "TOURNAMENT_K": TOURNAMENT_K,
            "CX_PROB": CX_PROB,
            "MUT_PROB": MUT_PROB,
            "MUT_SIGMA": MUT_SIGMA,
            "SEED": SEED,
            "N_WORKERS": N_WORKERS,
            "KEEP_RECENT_SUCCESS": KEEP_RECENT_SUCCESS,
            "DELETE_FAIL_CACHE": DELETE_FAIL_CACHE,
        },
        "best": {
            "map50": float(global_best_map),
            "chrom": global_best_chrom,
            "params": global_best_params,
            "work_dir": str(global_best_work_dir) if global_best_work_dir else "",
        }
    }

    best_json.write_text(json.dumps(best_payload, ensure_ascii=False, indent=2), encoding="utf-8")

    print("\n" + "=" * 60)
    print(f"[GAå®Œæˆ] run_dir={run_dir}")
    print(f"[GAå®Œæˆ] best mAP50 = {global_best_map:.6f}")
    print(f"[GAå®Œæˆ] best chrom = {global_best_chrom}")
    print(f"[GAå®Œæˆ] best params = {global_best_params}")
    print("=" * 60)

if __name__ == "__main__":
    main()