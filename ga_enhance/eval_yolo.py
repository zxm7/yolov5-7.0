# ga_enhance/eval_yolo.py
# =========================================================
# âœ… evaluate_paramsï¼šè¯„ä¼°â€œä¸€ä¸ªä¸ªä½“â€çš„ mAP50ï¼ˆæ”¯æŒå¹¶è¡Œï¼‰
#
# æ ¸å¿ƒæµç¨‹ï¼š
# 1) chrom -> paramsï¼ˆdecode_params æ¥è‡ª enhance_opsï¼Œå”¯ä¸€æƒå¨ï¼‰
# 2) ç”Ÿæˆå¢å¼ºåçš„ val_ga å›¾ç‰‡åˆ° work_dir/images
# 3) å¤åˆ¶ labels åˆ° work_dir/labels
# 4) ç”Ÿæˆ data_tmp.yaml æŒ‡å‘ work_dir/images
# 5) åœ¨ yolov5/ ä¸‹æ‰§è¡Œ val.py å¾—åˆ° mAP50
# 6) æˆåŠŸï¼šå†™ DONE + map50.txtï¼ˆå¯ç¼“å­˜å¤ç”¨ï¼‰
#    å¤±è´¥ï¼šå†™ FAIL + error.txt + stdout/stderrï¼ˆå®šä½åŸå› ï¼‰
#
# å¹¶è¡Œå®‰å…¨å…³é”®ç‚¹ï¼ˆå¿…çœ‹ï¼‰ï¼š
# - åŒä¸€ä¸ª chromï¼ˆåŒä¸€ä¸ª work_dirï¼‰åªèƒ½å…è®¸ä¸€ä¸ªè¿›ç¨‹â€œç”Ÿæˆå¢å¼ºå›¾ + è·‘ valâ€
# - ç”¨ LOCKï¼ˆåŸå­åˆ›å»ºï¼‰å®ç°äº’æ–¥ï¼šå…¶ä»–è¿›ç¨‹ç­‰å¾… DONEï¼ˆæˆ– FAILï¼‰
#
# ç¼“å­˜æ¸…ç†ï¼ˆé¿å…çˆ†ç›˜ï¼‰ï¼š
# - æä¾› prune_cache()ï¼šä¿ç•™æœ€è¿‘ N ä¸ª work_dirï¼Œä¸”æ€»å®¹é‡ä¸è¶…è¿‡ MAX_CACHE_GB
# =========================================================

from __future__ import annotations

import os
import re
import time
import shutil
import hashlib
import subprocess
from pathlib import Path
from dataclasses import dataclass
from typing import Optional, Dict, Any

import yaml
import numpy as np

# âœ… å”¯ä¸€æƒå¨ï¼šåªä» enhance_ops æ¥è§£ç  / å¢å¼º
from .enhance_ops import decode_params, enhance_val_images


# -------------------------------
# è·¯å¾„é…ç½®ï¼ˆæŒ‰ä½ çš„é¡¹ç›®ç»“æ„ï¼‰
# -------------------------------
# 1. é¡¹ç›®æ ¹ç›®å½•ï¼šä½  YOLOv5 ä»£ç å­˜æ”¾çš„ç»å¯¹è·¯å¾„
ROOT = Path("/home/zhangxu/yolov5-7.0")
# 2. YOLOv5 æ‰§è¡Œç›®å½•ï¼šä½ çš„æ ¹ç›®å½•æœ¬èº«å°±æ˜¯ YOLOv5 é¡¹ç›®
YOLO_DIR = ROOT
# 3. æ•°æ®é›†æ ¹ç›®å½•ï¼šæŒ‡å‘åŒ…å« images/ å’Œ labels/ çš„æ•°æ®é›†æ–‡ä»¶å¤¹
# æ³¨æ„ï¼šè¿™é‡Œè¦æŒ‡å‘ä½  8:1:1 åˆ’åˆ†åçš„é‚£ä¸ªæ–‡ä»¶å¤¹
SPLIT_DIR = ROOT / "datasets" / "UTDAC2020"
# 4. éªŒè¯é›†æ–‡ä»¶å¤¹åç§°ï¼šå¯¹åº”ä½ åˆ’åˆ†å‡ºçš„é‚£ 10% éªŒè¯é›†æ–‡ä»¶å¤¹å
VAL_NAME = "val"
# 5. åŸºç¡€é…ç½®æ–‡ä»¶ï¼šæŒ‡å‘ä½ è®­ç»ƒæ—¶ç”¨çš„é‚£ä¸ª utdac.yaml
BASE_DATA_YAML = ROOT / "data" / "utdac.yaml"
# 6. æƒé‡æ–‡ä»¶è·¯å¾„ï¼šæŒ‡å‘ä½ åˆšè·‘å‡ºæ¥çš„é‚£ä¸ª 0.797 åˆ†çš„æœ€å¥½æƒé‡ (YOLOv5n)
WEIGHTS = ROOT / "runs" / "train" / "yolov5n_scratch_baseline" / "weights" / "best.pt"
# 7. ç¼“å­˜ç›®å½•ï¼šç”¨äºå­˜æ”¾ GA è¿‡ç¨‹ä¸­äº§ç”Ÿçš„ä¸´æ—¶å›¾åƒ
CACHE_DIR = ROOT / "ga_cache"
CACHE_DIR.mkdir(parents=True, exist_ok=True)

# -------------------------------
# YOLO éªŒè¯å‚æ•°ï¼ˆå»ºè®®ä¿æŒæ ‡å‡†ï¼‰
# -------------------------------
IMG_SIZE = 640
CONF_THRES = 0.001      # âœ… mAP è¯„ä¼°é€šå¸¸ä½¿ç”¨ 0.001ï¼ˆé¿å… invalid resultsï¼‰
IOU_THRES = 0.6
DEVICE = ""            # å¼ºåˆ¶ç”¨ GPUï¼š0
YOLO_WORKERS = 0        # val.py çš„ dataloader workers
YOLO_BATCH_SIZE = 16     # æ§åˆ¶æ˜¾å­˜ï¼Œé˜²æ­¢ OOM
YOLO_HALF = True
# -------------------------------
# ç¼“å­˜æ§åˆ¶ï¼šé¿å…çˆ†ç›˜
# -------------------------------
KEEP_RECENT_N = 80       # è‡³å°‘ä¿ç•™æœ€è¿‘ 80 ä¸ª work_dirï¼ˆä½ å¯ä»¥æŒ‰ç¡¬ç›˜æ”¹ï¼‰
MAX_CACHE_GB = 25        # ga_cache æ€»å®¹é‡ä¸Šé™ï¼ˆGBï¼‰ï¼Œè¶…è¿‡åˆ™æŒ‰æ—§çš„å…ˆåˆ 


# -------------------------------
# æ—¥å¿—æ§åˆ¶
# -------------------------------
DEFAULT_QUIET_ENHANCE = True     # å¹¶è¡Œæ—¶å»ºè®® Trueï¼Œé¿å…ç»ˆç«¯åˆ·çˆ†
DEFAULT_VERBOSE = True           # True: æ‰“å°é˜¶æ®µä¿¡æ¯


@dataclass
class EvalResult:
    ok: int                 # 1æˆåŠŸ / 0å¤±è´¥
    map50: float            # æˆåŠŸä¸º [0,1]ï¼Œå¤±è´¥ä¸º -1
    map50_95: float  # ğŸŸ¢ æ–°å¢è¿™è¡Œ
    time_sec: float
    cache_hit: int          # 1=ç¼“å­˜å‘½ä¸­ / 0=å®é™…æ‰§è¡Œ
    work_dir: str
    msg: str


# -------------------------------
# å°å·¥å…·
# -------------------------------
_ANSI_RE = re.compile(r"\x1b\[[0-9;]*m")


def _log(msg: str, verbose: bool = True):
    if verbose:
        print(msg, flush=True)


def _write_text(p: Path, s: str):
    p.parent.mkdir(parents=True, exist_ok=True)
    p.write_text(s if s is not None else "", encoding="utf-8", errors="ignore")


def _stable_hash(chrom: np.ndarray) -> str:
    """
    ç”Ÿæˆç¨³å®š hashï¼šé¿å…æµ®ç‚¹æŠ–åŠ¨ & ç¼“å­˜è¯¯å‘½ä¸­ã€‚
    hash åªè·Ÿï¼š
      - VAL_NAMEï¼ˆæ¢éªŒè¯é›†åä¸è¯¯å‘½ä¸­æ—§ç¼“å­˜ï¼‰
      - chromï¼ˆé‡åŒ–åï¼‰
    """
    chrom = np.asarray(chrom, dtype=np.float32).reshape(-1)
    q = np.round(chrom, 6)
    key = f"{VAL_NAME}|" + ",".join([f"{x:.6f}" for x in q.tolist()])
    return hashlib.sha256(key.encode("utf-8")).hexdigest()[:16]


def _read_map50_from_results_csv(save_dir: Path) -> Optional[float]:
    """
    ä¼˜å…ˆä» yolov5 val è¾“å‡ºçš„ results.csv è¯»å– mAP@0.5
    æ¯”è§£æ stdout ç¨³å®šã€‚
    """
    # å…¼å®¹ä¸åŒç‰ˆæœ¬ç›®å½•ç»“æ„ï¼šå°è¯•å¤šä¸ªå€™é€‰è·¯å¾„
    candidates = [
        save_dir / "results.csv",
        save_dir.parent / "results.csv",
        save_dir / "results.txt",        # æœ‰äº›ç‰ˆæœ¬åªæœ‰ txt
        save_dir.parent / "results.txt",
    ]

    csv_path = next((p for p in candidates if p.exists() and p.suffix == ".csv"), None)
    if csv_path is None:
        return None

    import csv as _csv
    with csv_path.open("r", encoding="utf-8", errors="ignore") as f:
        reader = _csv.DictReader(f)
        rows = list(reader)
        if not rows:
            return None
        row = rows[-1]

    # å¸¸è§åˆ—åï¼ˆyolov5 ç‰ˆæœ¬å¯èƒ½ä¸åŒï¼‰
    for k in ["metrics/mAP_0.5", "mAP@0.5", "map50", "metrics/mAP50"]:
        if k in row:
            try:
                return float(row[k])
            except Exception:
                return None
    return None


def _read_map50_from_stdout(text: Optional[str]) -> Optional[float]:
    if text is None: return None # âœ… å¦‚æœæ²¡è¯»åˆ°æ–‡å­—ï¼Œç›´æ¥è¿”å›ç©ºï¼Œä¸å†æŠ¥é”™
    text = _ANSI_RE.sub("", text)


    m = re.search(
        r"^\s*all\s+\d+\s+\d+\s+[\d.]+\s+[\d.]+\s+([\d.]+)\s+[\d.]+\s*$",
        text,
        flags=re.MULTILINE,
    )
    if m:
        try:
            return float(m.group(1))
        except Exception:
            return None
    return None


def _dir_size_bytes(p: Path) -> int:
    total = 0
    if not p.exists():
        return 0
    for root, _, files in os.walk(p):
        for fn in files:
            try:
                total += (Path(root) / fn).stat().st_size
            except Exception:
                pass
    return total


def prune_cache(cache_dir: Path = CACHE_DIR,
                keep_recent_n: int = KEEP_RECENT_N,
                max_cache_gb: float = MAX_CACHE_GB,
                verbose: bool = False):
    """
    æ¸…ç† ga_cacheï¼šé¿å…é•¿æœŸè·‘ GA æŠŠç¡¬ç›˜åƒçˆ†ã€‚
    ç­–ç•¥ï¼š
      1) work_* æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œä¿ç•™æœ€è¿‘ keep_recent_n ä¸ª
      2) å‰©ä½™çš„æŒ‰æ—§åˆ°æ–°åˆ é™¤ï¼Œç›´åˆ°æ€»å®¹é‡ <= max_cache_gb
    æ³¨æ„ï¼š
      - æ­£åœ¨è¿è¡Œçš„ work_dir é‡Œæœ‰ RUNNING_* æˆ– LOCKï¼Œåˆ™è·³è¿‡
    """
    if not cache_dir.exists():
        return

    works = sorted(cache_dir.glob("work_*"), key=lambda p: p.stat().st_mtime, reverse=True)
    if not works:
        return

    # å…ˆç®—æ€»å®¹é‡
    total_bytes = sum(_dir_size_bytes(w) for w in works)
    max_bytes = int(max_cache_gb * (1024**3))

    # å…ˆä¿æŠ¤æœ€è¿‘ N ä¸ª
    protected = set(works[:keep_recent_n])

    # å¦‚æœå·²è¾¾æ ‡å°±ä¸åˆ 
    if total_bytes <= max_bytes:
        return

    # ä»æœ€æ—§å¼€å§‹åˆ 
    for w in reversed(works):
        if w in protected:
            continue

        # è·³è¿‡æ­£åœ¨è¿è¡Œ
        if any(w.glob("RUNNING_*")) or (w / "LOCK").exists():
            continue

        sz = _dir_size_bytes(w)
        try:
            shutil.rmtree(w, ignore_errors=True)
            total_bytes -= sz
            if verbose:
                _log(f"[ç¼“å­˜æ¸…ç†] åˆ é™¤ {w.name} é‡Šæ”¾ {sz/1024**3:.2f} GB", True)
        except Exception:
            pass

        if total_bytes <= max_bytes:
            break


# =========================================================
# âœ… è¯„ä¼°å‡½æ•°ï¼ˆå¹¶è¡Œå®‰å…¨ï¼‰
# =========================================================
def evaluate_params(
    chrom,
    eval_tag: str,
    force_rebuild: bool = False,
    quiet_enhance: bool = DEFAULT_QUIET_ENHANCE,
    verbose: bool = DEFAULT_VERBOSE,
    wait_lock_sec: int = 3600,
) -> EvalResult:
    """
    è¯„ä¼°ä¸€ä¸ªä¸ªä½“ï¼ˆå¯è¢«å¤šè¿›ç¨‹å¹¶è¡Œè°ƒç”¨ï¼‰ã€‚

    å‚æ•°ï¼š
      chrom: np.ndarrayï¼Œé•¿åº¦=DIMï¼Œå€¼âˆˆ[0,1]
      eval_tag: å”¯ä¸€æ ‡ç­¾ï¼ˆå»ºè®®åŒ…å« run_id + pid + eval_idxï¼‰
      force_rebuild: True æ— è§†ç¼“å­˜å¼ºåˆ¶é‡å»º
      quiet_enhance: True å¢å¼ºè¿‡ç¨‹ä¸åˆ·å±
      verbose: True æ‰“å°é˜¶æ®µä¿¡æ¯
      wait_lock_sec: ç­‰é”æœ€é•¿æ—¶é—´ï¼ˆç§’ï¼‰

    è¿”å›ï¼š
      EvalResult(ok/map50/time/cache_hit/work_dir/msg)
    """
    t0 = time.time()

    chrom = np.asarray(chrom, dtype=np.float32).reshape(-1)

    # ---------- 1) è§£ç å‚æ•° ----------
    try:
        params: Dict[str, Any] = decode_params(chrom)
    except Exception as e:
        return EvalResult(0, -1.0, time.time() - t0, 0, "", f"[è§£ç å¤±è´¥] {e}")

    # ---------- 2) work_dir ----------
    h = _stable_hash(chrom)
    work_dir = CACHE_DIR / f"work_{h}"
    done_flag = work_dir / "DONE"
    fail_flag = work_dir / "FAIL"
    lock_path = work_dir / "LOCK"

    # ---------- 3) ç¼“å­˜å‘½ä¸­ ----------
    if done_flag.exists() and (not force_rebuild):
        try:
            map50 = float((work_dir / "map50.txt").read_text(encoding="utf-8").strip())
            return EvalResult(1, map50, time.time() - t0, 1, str(work_dir), "cache_hit")
        except Exception:
            # ç¼“å­˜æŸåï¼šèµ°é‡å»º
            pass

    # force_rebuildï¼šæ¸…ç©ºæ—§ç›®å½•ï¼ˆæ³¨æ„ï¼šå¹¶è¡Œæƒ…å†µä¸‹ï¼Œåªæœ‰æ‹¿åˆ°é”çš„è¿›ç¨‹æ‰ä¼šåšï¼‰
    work_dir.mkdir(parents=True, exist_ok=True)

    # ---------- 4) åŸå­é”ï¼šå¹¶è¡Œäº’æ–¥ ----------
    got_lock = False
    if force_rebuild:
        # å¼ºåˆ¶é‡å»ºä¹Ÿå¾—æŠ¢é”ï¼Œå¦åˆ™ä¼šå’Œå…¶ä»–è¿›ç¨‹æ‰“æ¶
        pass

    try:
        fd = os.open(str(lock_path), os.O_CREAT | os.O_EXCL | os.O_WRONLY)
        os.close(fd)
        got_lock = True
    except FileExistsError:
        got_lock = False

    if not got_lock and (not force_rebuild):
        # è¯´æ˜åˆ«çš„è¿›ç¨‹æ­£åœ¨å¤„ç†åŒä¸€ä¸ª work_dirï¼šç­‰å¾… DONE/FAIL
        _log(f"[ç­‰å¾…] {work_dir.name} æ­£åœ¨è¢«å…¶ä»–è¿›ç¨‹è®¡ç®—ï¼Œç­‰å¾…ç»“æœ...", verbose)
        wait_t0 = time.time()
        while time.time() - wait_t0 < wait_lock_sec:
            if done_flag.exists():
                try:
                    map50 = float((work_dir / "map50.txt").read_text(encoding="utf-8").strip())
                    return EvalResult(1, map50, time.time() - t0, 1, str(work_dir), "cache_wait_hit")
                except Exception:
                    break
            if fail_flag.exists():
                # åˆ«äººå¤±è´¥äº†ï¼Œä½ å¯ä»¥é€‰æ‹©ï¼šç›´æ¥å¤±è´¥ or è‡ªå·±é‡è¯•
                err = (work_dir / "error.txt").read_text(encoding="utf-8", errors="ignore") if (work_dir / "error.txt").exists() else ""
                return EvalResult(0, -1.0, time.time() - t0, 0, str(work_dir), f"[ç­‰å¾…åå‘ç°å¤±è´¥] {err[:200]}")
            time.sleep(1.0)

        # è¶…æ—¶ï¼šä½ å¯ä»¥é€‰æ‹©è‡ªå·±å¼ºåˆ¶é‡å»ºï¼ˆè¿™é‡Œç›´æ¥è¿”å›å¤±è´¥ï¼Œé¿å…æ— é™è€—æ—¶ï¼‰
        return EvalResult(0, -1.0, time.time() - t0, 0, str(work_dir), "[ç­‰å¾…é”è¶…æ—¶] å¯èƒ½æœ‰å¡æ­»è¿›ç¨‹æœªé‡Šæ”¾ LOCK")

    # èƒ½èµ°åˆ°è¿™é‡Œï¼Œè¯´æ˜ï¼š
    # - got_lock=Trueï¼ˆæˆ‘æ¥å¹²æ´»ï¼‰
    # - æˆ– force_rebuild=Trueï¼ˆä¸‹é¢ä¹Ÿä¼šå¹²æ´»ï¼Œä½†ä¹Ÿå»ºè®® got_lock=True æ‰å®‰å…¨ï¼‰

    running_flag = work_dir / f"RUNNING_{os.getpid()}"
    running_flag.write_text(eval_tag, encoding="utf-8")

    try:
        # force_rebuildï¼šæ‹¿åˆ°é”åå†æ¸…ç©ºï¼Œé¿å…å¹¶è¡Œäº’åˆ 
        if force_rebuild and work_dir.exists():
            # æ³¨æ„ï¼šåˆ«æŠŠ LOCK åˆ äº†ï¼Œæ‰€ä»¥å…ˆè®°ä½ lock å·²åœ¨
            for child in work_dir.iterdir():
                if child.name in ("LOCK",):
                    continue
                if child.is_dir():
                    shutil.rmtree(child, ignore_errors=True)
                else:
                    try:
                        child.unlink()
                    except Exception:
                        pass

        # ---------- 5) æ£€æŸ¥æ•°æ®è·¯å¾„ (å·²æ ¹æ®ä½ çš„ images/val ç»“æ„ä¿®æ­£) ----------
        src_img_dir = SPLIT_DIR / "images" / VAL_NAME    # æ‹¼æ¥ç»“æœï¼š.../UTDAC2020/images/val
        src_label_dir = SPLIT_DIR / "labels" / VAL_NAME  # æ‹¼æ¥ç»“æœï¼š.../UTDAC2020/labels/val
        if not src_img_dir.exists():
            raise FileNotFoundError(f"[æ•°æ®é”™è¯¯] æ‰¾ä¸åˆ° {src_img_dir}")
        if not src_label_dir.exists():
            raise FileNotFoundError(f"[æ•°æ®é”™è¯¯] æ‰¾ä¸åˆ° {src_label_dir}")
        if not BASE_DATA_YAML.exists():
            raise FileNotFoundError(f"[é…ç½®é”™è¯¯] æ‰¾ä¸åˆ° base data.yaml: {BASE_DATA_YAML}")
        if not WEIGHTS.exists():
            raise FileNotFoundError(f"[æƒé‡é”™è¯¯] æ‰¾ä¸åˆ° weights: {WEIGHTS}")
        if not YOLO_DIR.exists():
            raise FileNotFoundError(f"[é…ç½®é”™è¯¯] æ‰¾ä¸åˆ° yolov5 ç›®å½•: {YOLO_DIR}")

        dst_img_dir = work_dir / "images"
        dst_label_dir = work_dir / "labels"
        dst_img_dir.mkdir(parents=True, exist_ok=True)
        dst_label_dir.mkdir(parents=True, exist_ok=True)

        # å†™ params.yamlï¼ˆæ–¹ä¾¿è¿½æº¯ï¼‰
        with (work_dir / "params.yaml").open("w", encoding="utf-8") as f:
            yaml.safe_dump(
                {"eval_tag": eval_tag, "chrom": chrom.tolist(), "params": params},
                f, allow_unicode=True
            )

        # ---------- 6) å¢å¼ºå›¾ç‰‡ ----------
        # âœ… åªæœ‰åœ¨æ²¡å›¾/æˆ– force_rebuild æ—¶æ‰å¢å¼ºï¼ˆå¦åˆ™ç›´æ¥å¤ç”¨ï¼‰
        need_enhance = force_rebuild or (not any(dst_img_dir.glob("*.jpg")) and not any(dst_img_dir.glob("*.png")))
        if need_enhance:
            _log(f"[å¢å¼º] {eval_tag} | work={work_dir.name} | å¼€å§‹å¢å¼º val({VAL_NAME}) ...", verbose)
            n = enhance_val_images(src_img_dir, dst_img_dir, params, quiet=quiet_enhance)
            if n <= 0:
                raise RuntimeError("[å¢å¼ºå¤±è´¥] è¾“å‡º 0 å¼ å›¾ç‰‡")
            _log(f"[å¢å¼º] {eval_tag} | å®Œæˆï¼š{n} å¼ ", verbose)
        else:
            _log(f"[å¢å¼º] {eval_tag} | å‘½ä¸­å¢å¼ºç¼“å­˜ï¼ˆè·³è¿‡å¢å¼ºï¼‰", verbose)

        # ---------- 7) labels å¤åˆ¶ ----------
        # âœ… åªåœ¨å¿…è¦æ—¶å¤åˆ¶ï¼Œé¿å…æ¯æ¬¡éƒ½æ‹·è´ 905 ä¸ª txt
        need_copy_labels = force_rebuild or (not any(dst_label_dir.glob("*.txt")))
        if need_copy_labels:
            _log(f"[æ ‡ç­¾] {eval_tag} | å¤åˆ¶ labels ...", verbose)
            for p in src_label_dir.glob("*.txt"):
                shutil.copy2(p, dst_label_dir / p.name)
            _log(f"[æ ‡ç­¾] {eval_tag} | labels å¤åˆ¶å®Œæˆ", verbose)
        else:
            _log(f"[æ ‡ç­¾] {eval_tag} | å‘½ä¸­ labels ç¼“å­˜ï¼ˆè·³è¿‡å¤åˆ¶ï¼‰", verbose)

        # ---------- 8) å†™ä¸´æ—¶ data yaml ----------
        data = yaml.safe_load(BASE_DATA_YAML.read_text(encoding="utf-8"))

        # å…³é”®ï¼šval æŒ‡å‘å¢å¼ºåçš„ images ç›®å½•
        data["val"] = str(dst_img_dir)

        # ä¿é™©ï¼šä¿è¯ nc/names ä¸ä¸¢ï¼ˆä½ çš„ base_data_yaml åº”è¯¥å·²æœ‰ï¼‰
        tmp_yaml = work_dir / f"data_tmp_{eval_tag}.yaml"
        tmp_yaml.write_text(yaml.safe_dump(data, allow_unicode=True), encoding="utf-8")

        # ---------- 9) è¿è¡Œ YOLOv5 val.py ----------
        yolo_out_root = work_dir / "yolo_val"
        yolo_out_root.mkdir(parents=True, exist_ok=True)

        cmd = [
            "python", "val.py",
            "--data", str(tmp_yaml),
            "--weights", str(WEIGHTS),
            "--imgsz", str(IMG_SIZE),
            "--conf-thres", str(CONF_THRES),
            "--iou-thres", str(IOU_THRES),
            "--device", DEVICE,
            "--workers", str(YOLO_WORKERS),
            "--batch-size", str(YOLO_BATCH_SIZE),
            "--project", str(yolo_out_root),
            "--name", eval_tag,
            "--exist-ok",
        ]
        if YOLO_HALF:
            cmd.append("--half")

        _log(f"[YOLO] {eval_tag} | å¼€å§‹éªŒè¯ï¼ˆå¯èƒ½éœ€è¦å‡ åç§’~å‡ åˆ†é’Ÿï¼‰...", verbose)
        proc = subprocess.run(
            cmd,
            cwd=str(YOLO_DIR),
            capture_output=True,
            text=True
        )

        # æ— è®ºæˆåŠŸå¤±è´¥ï¼Œéƒ½è½ç›˜ï¼Œæ–¹ä¾¿å®šä½
        _write_text(work_dir / "val_stdout.txt", proc.stdout)
        _write_text(work_dir / "val_stderr.txt", proc.stderr)

        if proc.returncode != 0:
            fail_flag.write_text(f"val.py returncode={proc.returncode}", encoding="utf-8")
            raise RuntimeError(f"[YOLOéªŒè¯å¤±è´¥] returncode={proc.returncode}ï¼Œçœ‹ {work_dir/'val_stderr.txt'}")

        # ---------- 10) è§£æ mAP50 ----------
        # yolov5 é»˜è®¤è¾“å‡ºåœ¨ï¼šyolo_out_root/eval_tag/
        save_dir = yolo_out_root / eval_tag

        map50 = _read_map50_from_results_csv(save_dir)
        if map50 is None:
            map50 = _read_map50_from_stdout(proc.stdout) or _read_map50_from_stdout(proc.stderr)

        if map50 is None:
            fail_flag.write_text("map50 parse failed", encoding="utf-8")
            raise RuntimeError(
                f"[è§£æå¤±è´¥] æ²¡æ‹¿åˆ° mAP50ã€‚è¯·çœ‹ï¼š\n"
                f"  {work_dir/'val_stdout.txt'}\n"
                f"  {work_dir/'val_stderr.txt'}"
            )

        # ---------- 11) æˆåŠŸï¼šå†™ DONE ----------
        (work_dir / "map50.txt").write_text(f"{float(map50):.6f}", encoding="utf-8")
        done_flag.write_text("ok", encoding="utf-8")
        if fail_flag.exists():
            try:
                fail_flag.unlink()
            except Exception:
                pass

        _log(f"[å®Œæˆ] {eval_tag} | mAP50={map50:.6f} | work={work_dir.name}", verbose)

        # ---------- 12) é¡ºæ‰‹æ¸…ç¼“å­˜ï¼ˆé¿å…çˆ†ç›˜ï¼‰ ----------
        # ä½ ä¹Ÿå¯ä»¥é€‰æ‹©åªåœ¨ ga_main æ¯ä»£ç»“æŸåå†è°ƒç”¨
        prune_cache(verbose=False)

        return EvalResult(1, float(map50), time.time() - t0, 0, str(work_dir), "ok")

    except Exception as e:
        _write_text(work_dir / "error.txt", str(e))
        fail_flag.write_text("fail", encoding="utf-8")
        _log(f"[å¤±è´¥] {eval_tag} | {e}", verbose)
        return EvalResult(0, -1.0, time.time() - t0, 0, str(work_dir), str(e))

    finally:
        # æ¸…ç† RUNNING
        if running_flag.exists():
            try:
                running_flag.unlink()
            except Exception:
                pass

        # é‡Šæ”¾ LOCKï¼ˆéå¸¸å…³é”®ï¼‰
        if lock_path.exists():
            try:
                lock_path.unlink()
            except Exception:
                pass
