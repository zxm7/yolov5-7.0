# ga_enhance/enhance_ops.py
# =========================================================
# âœ… å®Œæ•´ç‰ˆï¼šDIM=6 (æ–°å¢é”åŒ–æƒé‡ w_sharp æ§åˆ¶)
# âœ… åŒ…å«ï¼šè‰²å½©æ ¡æ­£ (Eq. 1-2)ã€å¤šç‰¹å¾ç”Ÿæˆ (Eq. 3-4)ã€æƒé‡è¯„ä¼° (Eq. 5-6)ã€é‡‘å­—å¡”èåˆ
# =========================================================

from __future__ import annotations
from pathlib import Path
import sys

import cv2
import numpy as np

# ğŸŸ¢ å®¹é”™å¤„ç†ï¼šç¦ç”¨ OpenCL
try:
    if hasattr(cv2, 'setUseOpenCL'):
        cv2.setUseOpenCL(False)
    elif hasattr(cv2, 'ocl') and hasattr(cv2.ocl, 'setUseOpenCL'):
        cv2.ocl.setUseOpenCL(False)
except Exception:
    pass

# 1. ç»´åº¦æ”¹ä¸º 7
DIM = 7

def decode_params(chrom) -> dict:
    chrom = np.asarray(chrom, dtype=float).reshape(-1)
    # å¢åŠ  g6 å¯¹åº”çº¢å…‰å¢ç›Š
    g0, g1, g2, g3, g4, g5, g6 = chrom.tolist()
    return {
        "eta1": g0,
        "eta2": g1,
        "gamma1": 0.8 + g2 * 3.0,
        "gamma2": 1.0 + g3 * 2.0,
        "gamma3": 1.0 + g4 * 2.0,
        "w_sharp": g5,
        "red_gain": 1.0 + g6 * 1.5   # ğŸŸ¢ æ–°å¢ï¼šçº¢å…‰å¢ç›ŠèŒƒå›´ [1.0, 2.5]
    }


# --- é‡‘å­—å¡”èåˆè¾…åŠ©å‡½æ•° (å¿…é¡»ä¿ç•™) ---

def _get_gaussian_pyramid(img, levels):
    pyramid = [img]
    temp = img.copy()
    for _ in range(levels - 1):
        temp = cv2.pyrDown(temp)
        pyramid.append(temp)
    return pyramid


def _get_laplacian_pyramid(img, levels):
    gauss = _get_gaussian_pyramid(img, levels)
    pyramid = []
    for i in range(levels - 1):
        size = (gauss[i].shape[1], gauss[i].shape[0])
        expanded = cv2.pyrUp(gauss[i + 1], dstsize=size)
        if expanded.shape != gauss[i].shape:
            expanded = cv2.resize(expanded, (gauss[i].shape[1], gauss[i].shape[0]))
        pyramid.append(gauss[i] - expanded)
    pyramid.append(gauss[-1])
    return pyramid


# --- ä¸»å¢å¼ºå‡½æ•° ---

def apply_enhancement(img_bgr: np.ndarray, params: dict) -> np.ndarray:
    # å½’ä¸€åŒ–è¾“å…¥
    img = img_bgr.astype(np.float32) / 255.0

    # ğŸŸ¢ æ–°å¢ï¼šçº¢è‰²é€šé“é¢„è¡¥å¿ (é’ˆå¯¹æ°´ä¸‹ç¯å¢ƒ)
    # åœ¨ BGR æ ¼å¼ä¸­ï¼Œç´¢å¼• 2 æ˜¯çº¢è‰²é€šé“
    r_gain = params.get("red_gain", 1.0)
    img[..., 2] = np.clip(img[..., 2] * r_gain, 0.0, 1.0)

    # 1. è‰²å½©æ ¡æ­£ (Color Correction Eq. 1-2) [cite: 106-109]
    means = np.mean(img, axis=(0, 1))
    idxs = np.argsort(means)
    idx_low, idx_med, idx_high = idxs[0], idxs[1], idxs[2]

    # ä¿æŒä¹‹å‰éªŒè¯è¿‡çš„æ¸©å’Œè¡¥å¿
    eta1, eta2 = float(params["eta1"]) * 0.5, float(params["eta2"]) * 0.5

    img_corr = img.copy()
    denom_med = (means[idx_high] + means[idx_med] + 1e-6)
    img_corr[..., idx_med] += eta1 * ((means[idx_high] - means[idx_med]) / denom_med) * img[..., idx_high]

    denom_low = (means[idx_high] + means[idx_low] + 1e-6)
    img_corr[..., idx_low] += eta2 * ((means[idx_high] - means[idx_low]) / denom_low) * img[..., idx_high]

    img_corr = np.clip(img_corr, 0.0, 1.0)

    # 2. å¤šç‰¹å¾ç”Ÿæˆ (Multi-feature Generation Eq. 3-4) [cite: 123-127]
    inputs = []

    # 2.1 é”åŒ–å›¾ I_sï¼šç”± GA åŸºå›  w_sharp æ§åˆ¶å¼ºåº¦
    # å¦‚æœ GA è®¤ä¸ºé”åŒ–ä¼¤å®³åˆ†æ•°ï¼Œå®ƒä¼šæŠŠ w_s æœå‘ 0
    w_s = params.get("w_sharp", 0.5)
    blur = cv2.GaussianBlur(img_corr, (0, 0), 5)
    details = img_corr - blur
    d_min, d_max = details.min(), details.max()
    details_norm = (details - d_min) / (d_max - d_min + 1e-6)
    inputs.append(np.clip(img_corr * (1 - w_s) + details_norm * w_s, 0, 1))

    # 2.2 3å¼  Gamma æ›å…‰å›¾
    for k in ["gamma1", "gamma2", "gamma3"]:
        inputs.append(np.power(img_corr, params[k]))

    # 3. æƒé‡è¯„ä¼° (Weighting Eq. 5-6) [cite: 133-134]
    weights = []
    sigma = 0.2
    for inp in inputs:
        gray = cv2.cvtColor((inp * 255).astype(np.uint8), cv2.COLOR_BGR2GRAY).astype(np.float32) / 255.0
        # æ›å…‰æƒé‡ (Exposure Map Eq. 5)
        E = np.exp(-((gray - 0.5) ** 2) / (2 * sigma ** 2))
        # å¯¹æ¯”åº¦æƒé‡ (Contrast Map Eq. 6)
        C = np.abs(cv2.Laplacian(gray, cv2.CV_32F))
        weights.append(E * C + 1e-6)

    w_sum = np.sum(weights, axis=0)
    norm_weights = [w / w_sum for w in weights]

    # 4. å¤šå°ºåº¦é‡‘å­—å¡”èåˆ (Pyramid Fusion Stage)
    levels = 5
    input_laps = [_get_laplacian_pyramid(inp, levels) for inp in inputs]
    weight_gauss = [_get_gaussian_pyramid(w, levels) for w in norm_weights]

    fused_pyramid = []
    for l in range(levels):
        fused_l = np.zeros_like(input_laps[0][l])
        for i in range(len(inputs)):
            fused_l += weight_gauss[i][l][..., np.newaxis] * input_laps[i][l]
        fused_pyramid.append(fused_l)

    # é‡æ„å›¾åƒ
    res = fused_pyramid[-1]
    for l in range(levels - 2, -1, -1):
        size = (fused_pyramid[l].shape[1], fused_pyramid[l].shape[0])
        res = cv2.pyrUp(res, dstsize=size)
        if res.shape != fused_pyramid[l].shape:
            res = cv2.resize(res, (fused_pyramid[l].shape[1], fused_pyramid[l].shape[0]))
        res += fused_pyramid[l]

    return (np.clip(res, 0.0, 1.0) * 255.0).astype(np.uint8)


def enhance_val_images(src_img_dir: Path, dst_img_dir: Path, params: dict, quiet: bool = True) -> int:
    src_img_dir, dst_img_dir = Path(src_img_dir), Path(dst_img_dir)
    dst_img_dir.mkdir(parents=True, exist_ok=True)
    img_paths = sorted([p for p in src_img_dir.glob("*") if p.suffix.lower() in [".jpg", ".jpeg", ".png"]])

    total = len(img_paths)
    if not quiet:
        print(f"\n[å¢å¼ºå¼€å§‹] ç›®æ ‡: {dst_img_dir.name}, å…± {total} å¼ ")

    n_ok = 0
    for i, p in enumerate(img_paths, 1):
        img = cv2.imread(str(p))
        if img is None: continue
        out = apply_enhancement(img, params)
        cv2.imwrite(str(dst_img_dir / p.name), out)
        n_ok += 1
        if not quiet and i % 10 == 0:
            sys.stdout.write(f"\r >> è¿›åº¦: {i}/{total} ({(i / total) * 100:.1f}%) ")
            sys.stdout.flush()

    if not quiet: print(f"\n[å®Œæˆ] æˆåŠŸå¤„ç† {n_ok} å¼ ")
    return n_ok